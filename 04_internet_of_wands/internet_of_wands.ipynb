{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Internet of Wands (WIP)\n",
    "\n",
    "This notebook is part of [*Practical Data Science for IoT*](https://github.com/pablodecm/datalab_ml_iot) tutorial by Pablo de Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Use Case\n",
    "\n",
    "The aim of this example is to demonstrate an end-to-end\n",
    "example of a machine learning for a (consumer) IoT application\n",
    "and remark the main challenges associated.\n",
    "\n",
    "**The use case chosen is a imaginary application where smartphones\n",
    "devices act as magic wands and we want to make a spell recognition\n",
    "system, which will be referred as Internet of Wands (IoW).**\n",
    "\n",
    "We will be focussing on how could we can collect and process \n",
    "for training and evaluating a model for such an application. We will also\n",
    "discuss how we could deploy to production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important Remark\n",
    "\n",
    "Most of the discussion and technology choices to follow are\n",
    "not unique of this application and could be readily applied\n",
    "to use cases  such as:\n",
    "- Human Activity Recognition with Wearables (e.g. running, lying down, driving or sitting)\n",
    "- Elderly fall/accident/emergency alert system\n",
    "- Possible Consumer Applications, for example:\n",
    "    - Gym Repetition Counter: identify exercise and count the reps based on wearables\n",
    "    - Parkinson Disease Early Detection system\n",
    "- Also broadly related with distributed training applications such a self-driving cars (e.g. Tesla Object recognition model [[1]](#References))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Important Aspects\n",
    "\n",
    "We will be discussing many aspects of the data cycle in supervised ML workflows for IoT, such as:\n",
    "\n",
    "- *Training Data Collection*:\n",
    "    - What device/hardware/configuration are we gonna use for a given application?\n",
    "    - Which sensors and additional data are relevant?\n",
    "    - Who/how is gonna be labelling/labelled the data? Do they need training to standarise the process?\n",
    "    - How much data we need for the application?\n",
    "    - Can we oversee and control the data collection process?\n",
    "    - How can we make data labelling it as easy as possible?\n",
    "    - Can we replicate the training conditions in production?\n",
    "    - **How expensive is it gonna be?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *Training Data Transport and Processing*:\n",
    "    - Where and how are we gonna store the data?\n",
    "    - How are we gonna transfer data from the devices to our data processing center?\n",
    "    - How much preprocessing we are gonna do on the device (i.e. edge computing)?\n",
    "    - How can we ensure security and privacy (e.g. transport encryption)?\n",
    "    - Have we test the data collection framework properly before data collection starts?\n",
    "    - **What volume of data is expected to flow to the servers per unit of time? Will the infrastructure scale and be robust enough?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *Data analysis and model building*:\n",
    "    - What do we want to do?\n",
    "    - Which tools/platforms/servers are we gonna use to explore the data?\n",
    "    - What type of data are we studying (e.g. time-series sensor, audio, images, text, etc)?\n",
    "    - What is the dimensionality and structure of the data?\n",
    "    - What are the possible factors that affect to the variance of\n",
    "      the data (e.g. data collection issues or changes in the\n",
    "      environment)?\n",
    "    - How easy will it be?\n",
    "    - Which techniques are more appropiate for a given type and volume of data?\n",
    "    - Can we complement with existing datasets or starting from a pre-trained model?\n",
    "    - How are we gonna to evaluate the performance to have unbiased measures?\n",
    "    - **What is the right trade-off between model complexity and\n",
    "    performance for the given application?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *Production Environment*:\n",
    "    - How are we gonna be using the resulting model in production?\n",
    "    - Can we deploy it first as a beta or internally to verify that it works as expected?\n",
    "    - Where are we gonna to carry out the model evaluation (e.g. our own remote servers, cloud or device)?\n",
    "    - Can we setup a loop monitoring and redeployment the model in production?\n",
    "    - **How much is expected to be gained by training with more data or improving the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Collection Infrastructure\n",
    "\n",
    "Here is an scheme of how the IOW data collection infrastructure,\n",
    "that uses common IoT technologies (e.g. a MQTT broker and node-red):\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/pablodecm/datalab_ml_iot/master/04_internet_of_wands/images/iow_infrastructure.png\" height=\"50%\" style=\"max-width: 80%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Collection Campaign\n",
    "\n",
    "Go with your smartphone to https://iow.pablodecm.com/ and generate magic spell demostrations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Downloading And Loading Latest Dataset\n",
    "\n",
    "You download the latest dataset from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/pablodecm/datalab_ml_iot/raw/master/04_internet_of_wands/iow_data.zip\"; unzip -o iow_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the Data\n",
    "\n",
    "We have do decide how we want to represent the data and also\n",
    "work on a custom reader for our set of json-based files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat iow_data/alohomora/Cedric_2579103d.01bba.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "example_file = \"iow_data/wingardium-leviosa/Peppapig_9b2bd7a9.0696f8.json\"\n",
    "\n",
    "example_df = pd.read_json(example_file)\n",
    "print(example_df.dtypes)\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply a series transformation and then invert to get it in a much better format\n",
    "accel_df = example_df.accel_data.apply(pd.Series).T\n",
    "accel_df[\"timestamp\"] = pd.to_timedelta(accel_df.timestamp, unit=\"ms\")\n",
    "accel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps of giro and accel sensors are high precision with a common origin\n",
    "gyro_df = example_df.gyro_data.apply(pd.Series).T\n",
    "gyro_df[\"timestamp\"] = pd.to_timedelta(gyro_df.timestamp, unit=\"ms\")\n",
    "gyro_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the minimum of timestamp as origin to have the same reference\n",
    "min_timestamp = min([accel_df.timestamp.min(),gyro_df.timestamp.min()])\n",
    "\n",
    "accel_df[\"timestamp\"] -= min_timestamp\n",
    "gyro_df[\"timestamp\"] -= min_timestamp\n",
    "# set first element to 0 to have the same start\n",
    "accel_df.loc[0,\"timestamp\"] = pd.Timedelta(0)\n",
    "gyro_df.loc[0,\"timestamp\"] = pd.Timedelta(0)\n",
    "accel_df = accel_df.set_index(\"timestamp\")\n",
    "gyro_df = gyro_df.set_index(\"timestamp\")\n",
    "\n",
    "accel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still the sampling is slightly different\n",
    "gyro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can resample to fix that\n",
    "resampled_accel_df = accel_df.resample(\"20ms\").mean().interpolate('time')\n",
    "resampled_gyro_df = gyro_df.resample(\"20ms\").mean().interpolate('time')\n",
    "\n",
    "resampled_accel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then finally merge\n",
    "merged_df = pd.merge(resampled_accel_df, resampled_gyro_df, \n",
    "                     left_index=True, right_index=True,\n",
    "                     suffixes=[\"_accel\",\"_gyro\"], how=\"inner\")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(12,12))\n",
    "\n",
    "merged_df.filter(regex=\"._accel\").plot(ax=axs[0])\n",
    "merged_df.filter(regex=\"._gyro\").plot(ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a function to do all the pre-processing for a given json file\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def load_df_from_iow_json(json_path: Path) -> pd.DataFrame:\n",
    "    \n",
    "    # load json file to dataframe\n",
    "    raw_df = pd.read_json(json_path)\n",
    "    \n",
    "    # convert to series to avoid having object elements\n",
    "    accel_df = raw_df.accel_data.apply(pd.Series).T\n",
    "    accel_df[\"timestamp\"] = pd.to_timedelta(accel_df.timestamp, unit=\"ms\")\n",
    "    gyro_df = raw_df.gyro_data.apply(pd.Series).T\n",
    "    gyro_df[\"timestamp\"] = pd.to_timedelta(gyro_df.timestamp, unit=\"ms\")\n",
    "    \n",
    "    # we can use the minimum of timestamp as origin to have the same reference\n",
    "    min_timestamp = min([accel_df.timestamp.min(),gyro_df.timestamp.min()])\n",
    "\n",
    "    # set the same timestamp origin\n",
    "    accel_df[\"timestamp\"] -= min_timestamp\n",
    "    gyro_df[\"timestamp\"] -= min_timestamp\n",
    "    # set first element to 0 to have the same start\n",
    "    accel_df.loc[0,\"timestamp\"] = pd.Timedelta(0)\n",
    "    gyro_df.loc[0,\"timestamp\"] = pd.Timedelta(0)\n",
    "    accel_df = accel_df.set_index(\"timestamp\")\n",
    "    gyro_df = gyro_df.set_index(\"timestamp\")\n",
    "    \n",
    "    # resample and interpolate to make homogeneous\n",
    "    resampled_accel_df = accel_df.resample(\"20ms\").mean().interpolate('time')\n",
    "    resampled_gyro_df = gyro_df.resample(\"20ms\").mean().interpolate('time')\n",
    "    \n",
    "    # merge in a single df\n",
    "    merged_df = pd.merge(resampled_accel_df, resampled_gyro_df, \n",
    "                         left_index=True, right_index=True,\n",
    "                         suffixes=[\"_accel\",\"_gyro\"], how=\"inner\")\n",
    "    \n",
    "    del raw_df[\"accel_data\"]\n",
    "    del raw_df[\"gyro_data\"]\n",
    "    \n",
    "    return merged_df, raw_df.loc[\"timestamp\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if it works from example\n",
    "load_df_from_iow_json(example_file)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_fields = [\"spell_select\",\"device_select\",\"wizard_name\"]\n",
    "data_path = Path(\"./iow_data\")\n",
    "\n",
    "merged_df_dict = {}\n",
    "for path in data_path.glob(\"*/*\"):\n",
    "    rel_path = path.relative_to(data_path)\n",
    "    merged_df, metadata = load_df_from_iow_json(path)\n",
    "    \n",
    "    spell_id = (rel_path.parent/rel_path.stem).as_posix()\n",
    "    key = tuple(metadata.loc[md_fields].to_list() + [spell_id])\n",
    "    merged_df_dict[key] = merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(merged_df_dict, names = (md_fields+ [\"spell_id\"]))\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = ['pablodecm']\n",
    "test_df = all_df.loc[(slice(None),slice(None),list(test_subset),slice(None)),:]\n",
    "all_others = set(all_df.index.get_level_values(2).unique()) - set(test_subset)\n",
    "train_df = all_df.loc[(slice(None),slice(None),list(all_others),slice(None)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to create a spell classifier based on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About high-resolution time in web applications:\n",
    "\n",
    "https://www.w3.org/TR/hr-time-2/#dfn-time-origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "For an overview of a state-of-the-art distributed training\n",
    "infrastructure including redeployment and the importance\n",
    "of edge in real-time applications you can check the Tesla Autonomy day presentation:\n",
    "\n",
    "- [1] [*Tesla Autonomy Day*](https://www.youtube.com/watch?v=Ucp0TTmvqOE)  Youtube video (+2hrs)\n",
    "\n",
    "There are several publications using combinations of RNNs and CNNs\n",
    "for dealing with IoT sensor data, for task such as\n",
    "Human Activity Recognition:\n",
    "- [2] Yao, Shuochao, et al. [*Deepsense: A unified deep learning framework for time-series mobile sensing data processing*](https://arxiv.org/abs/1611.01942) Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2017."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "rise": {
   "theme": "black"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
